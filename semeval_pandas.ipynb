{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRfg7td6KZaldBZAcaPzRo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abecode/630_django_example/blob/master/semeval_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9y1aoD_S6Je",
        "outputId": "5c2e3d21-59dc-444b-e0ce-c34e25f3e14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14.8M  100 14.8M    0     0  2700k      0  0:00:05  0:00:05 --:--:-- 3700k\n"
          ]
        }
      ],
      "source": [
        "# download the data\n",
        "# right now it's commented out to prevent accidental load to the semeval server\n",
        "!curl  https://propaganda.math.unipd.it/semeval2023task3/data/semeval2023task3bundle-v2.tgz  | tar -xz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/abecode/semeval2023.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLC5CsBVkDY5",
        "outputId": "1cb06040-afaf-4253-b3ed-a265f0414f54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semeval2023'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 4 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"semeval2023\")\n",
        "import semeval2023"
      ],
      "metadata": {
        "id": "HoZ5lg8gmWHd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = semeval2023.create_pandas_df()"
      ],
      "metadata": {
        "id": "t1bABt9US979"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idea make table like this\n",
        "\"\"\"\n",
        "| article id | partition | language | filename | genre label | framing labels|\n",
        "+-----------------------------------------------------------------------------\n",
        "\n",
        "eventually unpivot framing labels:\n",
        "economy, policy, national identity, resources/capacity, morality, fairness/equality, \n",
        "legality/constitution/jurisprudence, crime/punishment, security/defense, health/safety,\n",
        "quality of life, cultural identity, public opinion, political, external regulation/reputation,\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "pWqCEln8TzMq",
        "outputId": "9c5817fb-2318-4f49-c741-fe62b49777e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n| article id | partition | language | filename | genre label | framing labels|\\n+-----------------------------------------------------------------------------\\n\\neventually unpivot framing labels:\\neconomy, policy, national identity, resources/capacity, morality, fairness/equality, \\nlegality/constitution/jurisprudence, crime/punishment, security/defense, health/safety,\\nquality of life, cultural identity, public opinion, political, external regulation/reputation,\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "Ypw6T21yTGhU",
        "outputId": "71e841ee-33eb-46e8-db3b-bbc917e529c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id                                           sentence language  \\\n",
              "0           221  USA verbreiten gefakte Geschichten, um Russlan...       ge   \n",
              "1           223  Das neue Wahrheitsministerium des Biden-Regime...       ge   \n",
              "2           224  AfD: Allein in Hamburg: Eine halbe Milliarde E...       ge   \n",
              "3           225  Europol ist jetzt vollautorisiert zur EU-weite...       ge   \n",
              "4           226  WHO-Impfkampagne mit fatalen Folgen: Immer meh...       ge   \n",
              "...         ...                                                ...      ...   \n",
              "1229  999001323  Court orders White House to restore CNN corres...       en   \n",
              "1230  999001419  Trump Vows to Kick CNNâ€™s Acosta Out Again Pres...       en   \n",
              "1231  999001619  Guardian ups its vilification of Julian Assang...       en   \n",
              "1232  999001621  This Guardian Fake News Story Proves That The ...       en   \n",
              "1233  999001970  SNL Indian Comedian Silenced for \"Offensive Jo...       en   \n",
              "\n",
              "        genre                                             frames  \n",
              "0     opinion  Capacity_and_resources,Security_and_defense,Po...  \n",
              "1     opinion  Policy_prescription_and_evaluation,Cultural_id...  \n",
              "2     opinion  Legality_Constitutionality_and_jurisprudence,P...  \n",
              "3     opinion  Legality_Constitutionality_and_jurisprudence,P...  \n",
              "4     opinion  Policy_prescription_and_evaluation,Health_and_...  \n",
              "...       ...                                                ...  \n",
              "1229  opinion  Crime_and_punishment,Fairness_and_equality,Sec...  \n",
              "1230  opinion  Political,Policy_prescription_and_evaluation,L...  \n",
              "1231  opinion  Political,Crime_and_punishment,External_regula...  \n",
              "1232  opinion  Crime_and_punishment,Morality,External_regulat...  \n",
              "1233  opinion  Morality,Fairness_and_equality,Legality_Consti...  \n",
              "\n",
              "[1234 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-755353d5-0927-4046-a0c7-1072b88ba965\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "      <th>genre</th>\n",
              "      <th>frames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221</td>\n",
              "      <td>USA verbreiten gefakte Geschichten, um Russlan...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Capacity_and_resources,Security_and_defense,Po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>223</td>\n",
              "      <td>Das neue Wahrheitsministerium des Biden-Regime...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Policy_prescription_and_evaluation,Cultural_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>224</td>\n",
              "      <td>AfD: Allein in Hamburg: Eine halbe Milliarde E...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Legality_Constitutionality_and_jurisprudence,P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>225</td>\n",
              "      <td>Europol ist jetzt vollautorisiert zur EU-weite...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Legality_Constitutionality_and_jurisprudence,P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>226</td>\n",
              "      <td>WHO-Impfkampagne mit fatalen Folgen: Immer meh...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Policy_prescription_and_evaluation,Health_and_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>999001323</td>\n",
              "      <td>Court orders White House to restore CNN corres...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Crime_and_punishment,Fairness_and_equality,Sec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>999001419</td>\n",
              "      <td>Trump Vows to Kick CNNâ€™s Acosta Out Again Pres...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Political,Policy_prescription_and_evaluation,L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>999001619</td>\n",
              "      <td>Guardian ups its vilification of Julian Assang...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>999001621</td>\n",
              "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Crime_and_punishment,Morality,External_regulat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>999001970</td>\n",
              "      <td>SNL Indian Comedian Silenced for \"Offensive Jo...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Morality,Fairness_and_equality,Legality_Consti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1234 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-755353d5-0927-4046-a0c7-1072b88ba965')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-755353d5-0927-4046-a0c7-1072b88ba965 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-755353d5-0927-4046-a0c7-1072b88ba965');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## just English"
      ],
      "metadata": {
        "id": "2vKJiTnpTlFM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "39dCBjTI7I5h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n",
        "#df[df.frames.isna()] # some frames are None/NaN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "li4gBzpnBgeY",
        "outputId": "45c8cf7c-bec5-4372-a4cf-b1ed4227067f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id                                           sentence language  \\\n",
              "0           221  USA verbreiten gefakte Geschichten, um Russlan...       ge   \n",
              "1           223  Das neue Wahrheitsministerium des Biden-Regime...       ge   \n",
              "2           224  AfD: Allein in Hamburg: Eine halbe Milliarde E...       ge   \n",
              "3           225  Europol ist jetzt vollautorisiert zur EU-weite...       ge   \n",
              "4           226  WHO-Impfkampagne mit fatalen Folgen: Immer meh...       ge   \n",
              "...         ...                                                ...      ...   \n",
              "1229  999001323  Court orders White House to restore CNN corres...       en   \n",
              "1230  999001419  Trump Vows to Kick CNNâ€™s Acosta Out Again Pres...       en   \n",
              "1231  999001619  Guardian ups its vilification of Julian Assang...       en   \n",
              "1232  999001621  This Guardian Fake News Story Proves That The ...       en   \n",
              "1233  999001970  SNL Indian Comedian Silenced for \"Offensive Jo...       en   \n",
              "\n",
              "        genre                                             frames  \n",
              "0     opinion  Capacity_and_resources,Security_and_defense,Po...  \n",
              "1     opinion  Policy_prescription_and_evaluation,Cultural_id...  \n",
              "2     opinion  Legality_Constitutionality_and_jurisprudence,P...  \n",
              "3     opinion  Legality_Constitutionality_and_jurisprudence,P...  \n",
              "4     opinion  Policy_prescription_and_evaluation,Health_and_...  \n",
              "...       ...                                                ...  \n",
              "1229  opinion  Crime_and_punishment,Fairness_and_equality,Sec...  \n",
              "1230  opinion  Political,Policy_prescription_and_evaluation,L...  \n",
              "1231  opinion  Political,Crime_and_punishment,External_regula...  \n",
              "1232  opinion  Crime_and_punishment,Morality,External_regulat...  \n",
              "1233  opinion  Morality,Fairness_and_equality,Legality_Consti...  \n",
              "\n",
              "[1234 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45c535f7-b35b-4ad8-8b70-618b96558cd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "      <th>genre</th>\n",
              "      <th>frames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221</td>\n",
              "      <td>USA verbreiten gefakte Geschichten, um Russlan...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Capacity_and_resources,Security_and_defense,Po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>223</td>\n",
              "      <td>Das neue Wahrheitsministerium des Biden-Regime...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Policy_prescription_and_evaluation,Cultural_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>224</td>\n",
              "      <td>AfD: Allein in Hamburg: Eine halbe Milliarde E...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Legality_Constitutionality_and_jurisprudence,P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>225</td>\n",
              "      <td>Europol ist jetzt vollautorisiert zur EU-weite...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Legality_Constitutionality_and_jurisprudence,P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>226</td>\n",
              "      <td>WHO-Impfkampagne mit fatalen Folgen: Immer meh...</td>\n",
              "      <td>ge</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Policy_prescription_and_evaluation,Health_and_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>999001323</td>\n",
              "      <td>Court orders White House to restore CNN corres...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Crime_and_punishment,Fairness_and_equality,Sec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>999001419</td>\n",
              "      <td>Trump Vows to Kick CNNâ€™s Acosta Out Again Pres...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Political,Policy_prescription_and_evaluation,L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>999001619</td>\n",
              "      <td>Guardian ups its vilification of Julian Assang...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Political,Crime_and_punishment,External_regula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>999001621</td>\n",
              "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Crime_and_punishment,Morality,External_regulat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>999001970</td>\n",
              "      <td>SNL Indian Comedian Silenced for \"Offensive Jo...</td>\n",
              "      <td>en</td>\n",
              "      <td>opinion</td>\n",
              "      <td>Morality,Fairness_and_equality,Legality_Consti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1234 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c535f7-b35b-4ad8-8b70-618b96558cd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45c535f7-b35b-4ad8-8b70-618b96558cd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45c535f7-b35b-4ad8-8b70-618b96558cd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.language.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwUPOVAJWVWn",
        "outputId": "b695a1eb-eac7-490e-d201-679a49e95dd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ge', 'fr', 'ru', 'po', 'it', 'en'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sb"
      ],
      "metadata": {
        "id": "k8GZbCkLoFR0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb.countplot(\n",
        "    data=df,\n",
        "    x=\"language\",\n",
        "    hue=\"genre\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "oHW0fg-roWfi",
        "outputId": "31ec4b77-2cbf-4613-fa2f-adc9efb3401c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5af5962590>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make class weights\n",
        "total = len(df)\n",
        "num_reporting = len(df[df.genre == 'reporting'])\n",
        "num_opinion = len(df[df.genre == 'opinion'])\n",
        "num_satire = len(df[df.genre == 'satire'])\n",
        "print(num_reporting, num_opinion, num_satire, total)\n",
        "print(1/num_reporting* total, 1/num_opinion*total, 1/num_satire*total)\n",
        "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
        "# explains why *3 \n",
        "weights = {0: 1/num_reporting * total * 3,\n",
        "           1: 1/num_opinion * total * 3,\n",
        "           2: 1/num_satire*total * 3}\n",
        "\n",
        "biases = np.array([num_reporting/total, num_opinion/total, num_satire/total])\n",
        "print(biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhGac1vIs16b",
        "outputId": "1345fc0c-fe5a-44f3-9782-a106f2a54bfc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221 942 71 1234\n",
            "5.58371040723982 1.3099787685774946 17.380281690140844\n",
            "[0.17909238 0.76337115 0.05753647]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make train/validation sets\n",
        "# go thru each language\n",
        "# go thru each category\n",
        "# shuffle\n",
        "# 90/10 split?  There's not a lot of satire so maybe 80/20\n",
        "train_frac = .8\n",
        "train = pd.DataFrame()\n",
        "dev = pd.DataFrame()\n",
        "for lang in df.language.unique():\n",
        "  for genre in df.genre.unique():\n",
        "    #print(lang, genre, len(df[(df.language==lang) & (df.genre==genre)]))\n",
        "    tmp = df[(df.language==lang) & (df.genre==genre)]\n",
        "    tmp = tmp.sample(frac=1).reset_index(drop=True)\n",
        "    #print(np.ceil(len(tmp)*train_frac))\n",
        "    ceil = int(np.ceil(len(tmp)*train_frac)) \n",
        "    train = pd.concat([train, tmp[:ceil]])\n",
        "    dev = pd.concat([dev, tmp[ceil:]])\n",
        "    #break"
      ],
      "metadata": {
        "id": "Jwe2c2mQwu7Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train)+len(dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEjb87zJ3-Gh",
        "outputId": "88caaea7-7fac-4356-97e5-50f5511e891c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cf: https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
        "\n",
        "!pip install -U \"tensorflow==2.8.*\"\n",
        "!pip install -U \"tensorflow-text==2.8.*\"\n",
        "#!pip install -q tf-models-official==2.4.0\n",
        "!pip install -q tf-models-official\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp import optimization\n",
        "\n",
        "\n",
        "\n",
        "# map name to handle\n",
        "#'bert_multi_cased_L-12_H-768_A-12':\n",
        "#        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "# map model to preprocess\n",
        "#  'bert_multi_cased_L-12_H-768_A-12':\n",
        "#        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',        \n",
        "bert_preprocess_model = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3')\n",
        "bert_model = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4zCdKWt4d1X",
        "outputId": "a4efa1cd-3a1d-4f21-bee5-98722184096e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8.*\n",
            "  Downloading tensorflow-2.8.3-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497.9 MB 34 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.15.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.8 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.50.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (0.27.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (0.2.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4 MB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.12)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.*) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.3 tensorflow-estimator-2.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text==2.8.*\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.9 MB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.12)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.0.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.27.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2 MB 32.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 62.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 238 kB 75.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 578.0 MB 15 kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.9 MB 58.7 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43 kB 2.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3 MB 61.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.2 MB 1.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116 kB 77.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352 kB 74.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 62.7 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.9 MB 56.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.7 MB 47.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438 kB 57.9 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text_test = ['this is such an amazing movie!']\n",
        "text_test = train.sentence[0:2]\n",
        "print(text_test)\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "print(text_preprocessed.values())\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, ]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, ]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, ]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u455j1mI7PbZ",
        "outputId": "ea23bba3-4d95-452f-a831-7faec0e253b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Russische Eisbrecher â€“ oder: Wie sich der West...\n",
            "1    Schlechter Scherz: Luisa Neubauer will Pipelin...\n",
            "Name: sentence, dtype: object\n",
            "dict_values([<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "      dtype=int32)>, <tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "      dtype=int32)>, <tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
            "array([[   101,  44235,  99119,  13724,  13396,    100,  10760,    131,\n",
            "         23789,  10372,  10118,  19450,    113,  10515,    114,  10106,\n",
            "         10118,  67552,  13434,  15498,    148,  11297,    187,  50784,\n",
            "         50130,    107,  31385,  10242,  37343,  10457,  11036,  43352,\n",
            "         26053,  10123,    117,    112,    187,  45942,  69828,  10162,\n",
            "         11190,  10915,  64335,  10123,    112,  14095,  10240,  21253,\n",
            "         10123,    119,    107,  13830,  72439,  29712,  19584,  20458,\n",
            "         10298,  10359,  10118,  65420,  10140,  10174,  12867,  10119,\n",
            "         18558,  86291,  40100,    119,  38141,  10632,  60696,  97615,\n",
            "         10133,  53978,  10140,  20648,  25581,  52535,  10136,  14321,\n",
            "         37324,  10599,  16518,  10166,  23754,  40995,  37917,  10211,\n",
            "         67552,  22190,  29839,    117,  10106,  54861,  15032,  22460,\n",
            "         10304, 105184,  10115,    117,  15032,  22460,    117,  10242,\n",
            "         58720,  10107,  63105,  10140,  28099,  34310,  10118,  22223,\n",
            "         24569,  19180,    119,  10796,  11218,  22171,  10884,  10790,\n",
            "         10128,  19489,  10139,  30186,  72397,  10107,  10329,    102],\n",
            "       [   101,  55260,  41058,  24334,  55260,  14206,  10305,    131,\n",
            "         37335,  57617,  10165,  11337,  38329,  77558,  10238,   1725,\n",
            "         10106,  10128,  48903,  64715,  10136,    100,  10167,  10745,\n",
            "         83019,    118,  14994,  58768,  11587,  10562,  10128,  17486,\n",
            "         74122,  12926,  10118,  67855,  11044,  16997,  10681,  10848,\n",
            "        108974,  39925,  15008,  10269,  77160,  10329,  10128,  10452,\n",
            "         46123,  27195,  90378,    118,  38329,  77558,  10238,  38478,\n",
            "         82272,  11127,  10485,  10465,    119,  10672,  24577,  17375,\n",
            "         32352,  47337,  10221,  44554,  15942,  39802,    119,  41523,\n",
            "         55592,  98170,  91682,  33963,  35159,  10496,    117,  10953,\n",
            "         33963,  10128,  38329,  77558,  10238,  10106,  10128,  48903,\n",
            "         64715,  10136,  13746,    119,    100,  37335,  57617,  10165,\n",
            "         10130,  10290,  12699,  27495,  27295,  23455,  14786,    119,\n",
            "         10912,  10762,  79881,    117,  10128,  10242, 110749,  10166,\n",
            "          1725,  30767,  10107,  10142,  21508,    100,  10329,  83019,\n",
            "         39969,  92182,    119,  57617,  10165,  10298,  10106,    102]],\n",
            "      dtype=int32)>])\n",
            "Keys       : ['input_type_ids', 'input_mask', 'input_word_ids']\n",
            "Shape      : (2, 128)\n",
            "Word Ids   : [   101  44235  99119  13724  13396    100  10760    131  23789  10372\n",
            "  10118  19450    113  10515    114  10106  10118  67552  13434  15498\n",
            "    148  11297    187  50784  50130    107  31385  10242  37343  10457\n",
            "  11036  43352  26053  10123    117    112    187  45942  69828  10162\n",
            "  11190  10915  64335  10123    112  14095  10240  21253  10123    119\n",
            "    107  13830  72439  29712  19584  20458  10298  10359  10118  65420\n",
            "  10140  10174  12867  10119  18558  86291  40100    119  38141  10632\n",
            "  60696  97615  10133  53978  10140  20648  25581  52535  10136  14321\n",
            "  37324  10599  16518  10166  23754  40995  37917  10211  67552  22190\n",
            "  29839    117  10106  54861  15032  22460  10304 105184  10115    117\n",
            "  15032  22460    117  10242  58720  10107  63105  10140  28099  34310\n",
            "  10118  22223  24569  19180    119  10796  11218  22171  10884  10790\n",
            "  10128  19489  10139  30186  72397  10107  10329    102]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlbbxKFc7w-A",
        "outputId": "8696fcec-12f5-4cfc-b023-0dae77e25708"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pooled Outputs Shape:(2, 768)\n",
            "Pooled Outputs Values:[ 0.11456756 -0.0377249   0.16344944 -0.11571344  0.02567197  0.16312352\n",
            "  0.05548561  0.19079809 -0.2658641   0.16816828  0.06465182 -0.11564051]\n",
            "Sequence Outputs Shape:(2, 128, 768)\n",
            "Sequence Outputs Values:[[-4.7596633e-02  1.4011562e-04 -1.6286778e-01 ...  1.2299532e-01\n",
            "   1.3017072e-01 -1.3982660e-01]\n",
            " [ 6.4514950e-02  2.1338992e-01 -4.0004185e-01 ...  2.2141166e-01\n",
            "   7.9296276e-02 -1.9122218e-01]\n",
            " [-1.4208592e-02 -2.2478569e-01 -9.7470880e-03 ...  4.3504390e-01\n",
            "  -3.5772157e-01 -2.9318327e-01]\n",
            " ...\n",
            " [-3.6337006e-01 -1.5520789e-02  1.4536758e-01 ...  1.2789600e+00\n",
            "  -4.3837734e-02 -9.9978298e-02]\n",
            " [-3.9963630e-01  2.2052668e-02  4.5438302e-01 ...  7.5045526e-01\n",
            "  -3.5094079e-01  1.5382430e-01]\n",
            " [ 3.3721715e-01 -3.6591440e-01 -4.5167953e-01 ...  2.7367041e-01\n",
            "  -9.4314329e-02  2.8106049e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  #preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  #encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoded_inputs = bert_preprocess_model(text_input)\n",
        "  #encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  #outputs = encoder(encoder_inpnuts)\n",
        "  outputs = bert_model(encoded_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.3)(net)\n",
        "  # 3 class classification\n",
        "  net = tf.keras.layers.Dense(3,\n",
        "                              #activation=None,\n",
        "                              activation='softmax', \n",
        "                              name='classifier',\n",
        "                              bias_initializer=tf.keras.initializers.Constant(biases))(net)\n",
        "  # net = tf.keras.layers.CategoryEncoding(\n",
        "  #   num_tokens=3, output_mode='multi_hot', sparse=False, name='classifier'\n",
        "  # )\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "rEDY8gJh4UrU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kjXMVAm8Kkt",
        "outputId": "7aa2f7db-f0dc-4bc3-f723-0dcf6e3e2544"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.5959352  0.5998062  0.55151296]\n",
            " [0.6003193  0.59784794 0.5490165 ]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "WjKvwiw99xES",
        "outputId": "39de395c-9f57-4e74-dd3b-1e413ae503fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert labels to one hot encoding\n",
        "label_dict = {\n",
        "     'reporting': [1, 0, 0],\n",
        "     'opinion': [0, 1, 0],\n",
        "     'satire': [0, 0, 1],\n",
        "}\n",
        "label_dict2 = {\n",
        "    'reporting': 0,\n",
        "    'opinion': 1,\n",
        "    'satire': 2,\n",
        "}\n",
        "#coded_labels = list(map(lambda x: label_dict2[x], labels))\n",
        "train['coded_labels'] = list(map(lambda x: label_dict2[x], train.genre))\n",
        "dev['coded_labels'] = list(map(lambda x: label_dict2[x], dev.genre))"
      ],
      "metadata": {
        "id": "hZPcIhto95LR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "steps_per_epoch = 900#tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "metadata": {
        "id": "BfUUL0fr-h3V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#metrics = tf.metrics.BinaryAccuracy()\n",
        "#metrics = tf.metrics.CategoricalCrossentropy()\n",
        "metrics = tf.metrics.SparseCategoricalAccuracy()\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "XPDAJa5X-pS0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training model with mbert encoder')\n",
        "#tf.config.run_functions_eagerly(True)\n",
        "history = classifier_model.fit(x=tf.constant(train.sentence),\n",
        "                               y=tf.constant(train.coded_labels),\n",
        "                               #x=sentences,\n",
        "                               #y=labels,\n",
        "                               validation_data=(tf.constant(dev.sentence), \n",
        "                                                tf.constant(dev.coded_labels)),\n",
        "                               #validation_split=.2,\n",
        "                               epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGBenxq8-skj",
        "outputId": "c502a84c-65a1-4597-dd8c-fe6ef7636bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with mbert encoder\n",
            "Epoch 1/300\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:5583: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 31s 525ms/step - loss: 0.9546 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.9320 - val_sparse_categorical_accuracy: 0.5649\n",
            "Epoch 2/300\n",
            "32/32 [==============================] - 14s 434ms/step - loss: 0.9555 - sparse_categorical_accuracy: 0.5296 - val_loss: 0.9318 - val_sparse_categorical_accuracy: 0.5649\n",
            "Epoch 3/300\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.9540 - sparse_categorical_accuracy: 0.5186 - val_loss: 0.9316 - val_sparse_categorical_accuracy: 0.5690\n",
            "Epoch 4/300\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 0.9503 - sparse_categorical_accuracy: 0.5658 - val_loss: 0.9312 - val_sparse_categorical_accuracy: 0.5732\n",
            "Epoch 5/300\n",
            "32/32 [==============================] - 14s 454ms/step - loss: 0.9519 - sparse_categorical_accuracy: 0.5357 - val_loss: 0.9308 - val_sparse_categorical_accuracy: 0.5732\n",
            "Epoch 6/300\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.9597 - sparse_categorical_accuracy: 0.4965 - val_loss: 0.9302 - val_sparse_categorical_accuracy: 0.5774\n",
            "Epoch 7/300\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.9553 - sparse_categorical_accuracy: 0.5176 - val_loss: 0.9296 - val_sparse_categorical_accuracy: 0.5816\n",
            "Epoch 8/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9489 - sparse_categorical_accuracy: 0.5246 - val_loss: 0.9289 - val_sparse_categorical_accuracy: 0.5858\n",
            "Epoch 9/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9532 - sparse_categorical_accuracy: 0.5266 - val_loss: 0.9280 - val_sparse_categorical_accuracy: 0.5900\n",
            "Epoch 10/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.9452 - sparse_categorical_accuracy: 0.5497 - val_loss: 0.9270 - val_sparse_categorical_accuracy: 0.6151\n",
            "Epoch 11/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9474 - sparse_categorical_accuracy: 0.5558 - val_loss: 0.9260 - val_sparse_categorical_accuracy: 0.6151\n",
            "Epoch 12/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9496 - sparse_categorical_accuracy: 0.4995 - val_loss: 0.9249 - val_sparse_categorical_accuracy: 0.6192\n",
            "Epoch 13/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9538 - sparse_categorical_accuracy: 0.5126 - val_loss: 0.9236 - val_sparse_categorical_accuracy: 0.6192\n",
            "Epoch 14/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9535 - sparse_categorical_accuracy: 0.5106 - val_loss: 0.9223 - val_sparse_categorical_accuracy: 0.6402\n",
            "Epoch 15/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9395 - sparse_categorical_accuracy: 0.5477 - val_loss: 0.9209 - val_sparse_categorical_accuracy: 0.6402\n",
            "Epoch 16/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9495 - sparse_categorical_accuracy: 0.5296 - val_loss: 0.9193 - val_sparse_categorical_accuracy: 0.6653\n",
            "Epoch 17/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9436 - sparse_categorical_accuracy: 0.5477 - val_loss: 0.9178 - val_sparse_categorical_accuracy: 0.6736\n",
            "Epoch 18/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9440 - sparse_categorical_accuracy: 0.5407 - val_loss: 0.9160 - val_sparse_categorical_accuracy: 0.6862\n",
            "Epoch 19/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.9373 - sparse_categorical_accuracy: 0.5598 - val_loss: 0.9143 - val_sparse_categorical_accuracy: 0.6904\n",
            "Epoch 20/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9297 - sparse_categorical_accuracy: 0.5829 - val_loss: 0.9124 - val_sparse_categorical_accuracy: 0.6987\n",
            "Epoch 21/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.9323 - sparse_categorical_accuracy: 0.5719 - val_loss: 0.9104 - val_sparse_categorical_accuracy: 0.7071\n",
            "Epoch 22/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.9327 - sparse_categorical_accuracy: 0.5688 - val_loss: 0.9083 - val_sparse_categorical_accuracy: 0.7155\n",
            "Epoch 23/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9287 - sparse_categorical_accuracy: 0.5658 - val_loss: 0.9063 - val_sparse_categorical_accuracy: 0.7238\n",
            "Epoch 24/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.9320 - sparse_categorical_accuracy: 0.5739 - val_loss: 0.9041 - val_sparse_categorical_accuracy: 0.7322\n",
            "Epoch 25/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9258 - sparse_categorical_accuracy: 0.5759 - val_loss: 0.9018 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 26/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9227 - sparse_categorical_accuracy: 0.5829 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 27/300\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 0.9175 - sparse_categorical_accuracy: 0.6040 - val_loss: 0.8969 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 28/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9115 - sparse_categorical_accuracy: 0.6121 - val_loss: 0.8943 - val_sparse_categorical_accuracy: 0.7406\n",
            "Epoch 29/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9248 - sparse_categorical_accuracy: 0.5799 - val_loss: 0.8918 - val_sparse_categorical_accuracy: 0.7490\n",
            "Epoch 30/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9125 - sparse_categorical_accuracy: 0.6312 - val_loss: 0.8891 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 31/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9173 - sparse_categorical_accuracy: 0.6050 - val_loss: 0.8864 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 32/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.9017 - sparse_categorical_accuracy: 0.6312 - val_loss: 0.8836 - val_sparse_categorical_accuracy: 0.7531\n",
            "Epoch 33/300\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 0.9109 - sparse_categorical_accuracy: 0.6141 - val_loss: 0.8808 - val_sparse_categorical_accuracy: 0.7573\n",
            "Epoch 34/300\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.9061 - sparse_categorical_accuracy: 0.6000 - val_loss: 0.8779 - val_sparse_categorical_accuracy: 0.7657\n",
            "Epoch 35/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8984 - sparse_categorical_accuracy: 0.6382 - val_loss: 0.8748 - val_sparse_categorical_accuracy: 0.7657\n",
            "Epoch 36/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.8993 - sparse_categorical_accuracy: 0.6452 - val_loss: 0.8717 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 37/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8915 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.8685 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 38/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8910 - sparse_categorical_accuracy: 0.6221 - val_loss: 0.8652 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 39/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.8893 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.8619 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 40/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8813 - sparse_categorical_accuracy: 0.6583 - val_loss: 0.8586 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 41/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8837 - sparse_categorical_accuracy: 0.6513 - val_loss: 0.8552 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 42/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8901 - sparse_categorical_accuracy: 0.6452 - val_loss: 0.8518 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 43/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8857 - sparse_categorical_accuracy: 0.6472 - val_loss: 0.8483 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 44/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8777 - sparse_categorical_accuracy: 0.6613 - val_loss: 0.8448 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 45/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8663 - sparse_categorical_accuracy: 0.6784 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 46/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8652 - sparse_categorical_accuracy: 0.6935 - val_loss: 0.8377 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 47/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8633 - sparse_categorical_accuracy: 0.6874 - val_loss: 0.8340 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 48/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8579 - sparse_categorical_accuracy: 0.6995 - val_loss: 0.8303 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 49/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8504 - sparse_categorical_accuracy: 0.7226 - val_loss: 0.8266 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 50/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8543 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.8229 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 51/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8515 - sparse_categorical_accuracy: 0.6945 - val_loss: 0.8193 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 52/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8439 - sparse_categorical_accuracy: 0.7015 - val_loss: 0.8156 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 53/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8452 - sparse_categorical_accuracy: 0.7015 - val_loss: 0.8118 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 54/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.8365 - sparse_categorical_accuracy: 0.7216 - val_loss: 0.8079 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 55/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8362 - sparse_categorical_accuracy: 0.7206 - val_loss: 0.8041 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 56/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8238 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.8003 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 57/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8330 - sparse_categorical_accuracy: 0.7196 - val_loss: 0.7964 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 58/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.8312 - sparse_categorical_accuracy: 0.7206 - val_loss: 0.7926 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 59/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8169 - sparse_categorical_accuracy: 0.7357 - val_loss: 0.7887 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 60/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8206 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.7849 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 61/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8197 - sparse_categorical_accuracy: 0.7296 - val_loss: 0.7811 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 62/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8138 - sparse_categorical_accuracy: 0.7347 - val_loss: 0.7773 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 63/300\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.8014 - sparse_categorical_accuracy: 0.7437 - val_loss: 0.7735 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 64/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7951 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.7698 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 65/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.8046 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.7661 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 66/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7943 - sparse_categorical_accuracy: 0.7427 - val_loss: 0.7624 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 67/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.7952 - sparse_categorical_accuracy: 0.7508 - val_loss: 0.7587 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 68/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7955 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 69/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7827 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.7516 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 70/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7480 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 71/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7815 - sparse_categorical_accuracy: 0.7487 - val_loss: 0.7445 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 72/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7774 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.7409 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 73/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7813 - sparse_categorical_accuracy: 0.7497 - val_loss: 0.7373 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 74/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7665 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.7339 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 75/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7583 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.7305 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 76/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.7664 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 77/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7527 - sparse_categorical_accuracy: 0.7548 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 78/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.7611 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 79/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.7477 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 80/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7545 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.7145 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 81/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 82/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7554 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.7085 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 83/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7422 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.7058 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 84/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7449 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.7029 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 85/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7341 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.7004 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 86/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.7321 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 87/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7378 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6951 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 88/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.7337 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6927 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 89/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7307 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 90/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7340 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 91/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.7214 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 92/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7252 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6835 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 93/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7231 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6814 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 94/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7179 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 95/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7160 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 96/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7190 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 97/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7171 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 98/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 99/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7157 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6706 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 100/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.7162 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 101/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7130 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6674 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 102/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.7099 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 103/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 104/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7054 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 105/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7012 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 106/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.7023 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 107/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.7037 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 108/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7029 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6584 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 109/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7012 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6574 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 110/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.7004 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6564 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 111/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6969 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 112/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.6547 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 113/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6967 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 114/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6977 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 115/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6947 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6524 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 116/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6937 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 117/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6507 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 118/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7047 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6501 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 119/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6956 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6495 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 120/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 121/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6974 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6483 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 122/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 123/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6472 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 124/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 125/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6851 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 126/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6894 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6457 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 127/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.7022 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6452 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 128/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6949 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6449 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 129/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6960 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6445 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 130/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6897 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 131/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6438 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 132/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6434 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 133/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6431 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 134/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6428 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 135/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 136/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6421 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 137/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 138/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 139/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6843 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 140/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6889 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 141/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6902 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 142/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 143/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 144/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 145/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6853 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6398 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 146/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6396 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 147/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6840 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6395 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 148/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6895 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6393 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 149/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6885 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6391 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 150/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6389 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 151/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 152/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6882 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 153/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 154/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 155/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6381 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 156/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6848 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 157/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6829 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6378 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 158/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6823 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 159/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6905 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 160/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6374 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 161/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 162/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6371 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 163/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 164/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6369 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 165/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6877 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6368 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 166/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6881 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 167/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6858 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6365 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 168/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6364 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 169/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6363 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 170/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6820 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6362 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 171/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6847 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6360 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 172/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6765 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6360 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 173/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 174/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6821 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6357 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 175/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 176/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6814 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6356 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 177/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6355 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 178/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6763 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6354 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 179/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6812 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 180/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6826 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 181/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6834 - sparse_categorical_accuracy: 0.7578 - val_loss: 0.6351 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 182/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6816 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6350 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 183/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6736 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 184/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6348 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 185/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 186/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6834 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6347 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 187/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 188/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 189/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6750 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6345 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 190/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6344 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 191/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6343 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 192/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6763 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6343 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 193/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6816 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 194/300\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.6763 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6342 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 195/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6341 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 196/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6789 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 197/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6772 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 198/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6771 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 199/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 200/300\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.6826 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6336 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 201/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6834 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6336 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 202/300\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.6741 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 203/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6750 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 204/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6775 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6333 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 205/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6846 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6332 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 206/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6833 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 207/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 208/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6796 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6330 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 209/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6803 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6330 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 210/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6862 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6329 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 211/300\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6775 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 212/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6778 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6328 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 213/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6327 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 214/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6781 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 215/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6816 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 216/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6764 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6325 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 217/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 218/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6719 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6324 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 219/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6323 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 220/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6782 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 221/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 222/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6816 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 223/300\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 224/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 225/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6320 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 226/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 227/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6753 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6319 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 228/300\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6794 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 229/300\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6783 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6318 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 230/300\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 231/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6731 - sparse_categorical_accuracy: 0.7598 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 232/300\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6732 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6317 - val_sparse_categorical_accuracy: 0.7741\n",
            "Epoch 233/300\n",
            "29/32 [==========================>...] - ETA: 1s - loss: 0.6826 - sparse_categorical_accuracy: 0.7597"
          ]
        }
      ]
    }
  ]
}